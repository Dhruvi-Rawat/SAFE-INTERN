# app.py
"""
SAFE-INTERN Streamlit UI

Pipeline:
User Input
‚Üí input_router
‚Üí intake_agent (LLM / fallback)
‚Üí planner_agent (CrewAI)
‚Üí company + payment + behavior + ml agents
‚Üí risk_engine
‚Üí explanation_engine
‚Üí guardrails
‚Üí UI output
"""

import streamlit as st

# ---------- INTERNAL IMPORTS ----------
from intake.input_router import route_input
from intake.intake_agent import run_intake
from agents.planner_agent import run_planner
from utils.risk_engine import calculate_risk
from utils.explanation_engine import generate_explanation
from utils.guardrails import apply_full_guardrails


# ---------- STREAMLIT CONFIG ----------
st.set_page_config(
    page_title="SAFE-INTERN",
    page_icon="üõ°Ô∏è",
    layout="centered"
)

st.title("üõ°Ô∏è SAFE-INTERN")
st.caption("Internship Risk Advisory System")

st.markdown(
    """
Paste an internship message, email, offer letter, or job description below.

This system provides **advisory insights only**  
‚Äî it does **NOT** make accusations or legal claims.
"""
)

# ---------- USER INPUT ----------
user_text = st.text_area(
    label="Internship Communication",
    height=260,
    placeholder="Paste internship email / WhatsApp message / offer letter text here..."
)

analyze_button = st.button("Analyze Internship Risk")


# ---------- MAIN PIPELINE ----------
if analyze_button:
    if not user_text.strip():
        st.warning("Please enter internship-related text to analyze.")
    else:
        with st.spinner("Analyzing communication‚Ä¶"):
            try:
                # 1Ô∏è‚É£ Input routing (text / url / pdf support)
                routed_text = route_input(text_input=user_text)

                # 2Ô∏è‚É£ Intake agent (LLM or fallback)
                intake_schema = run_intake(routed_text)

                # 3Ô∏è‚É£ Planner + CrewAI agents
                agent_results = run_planner(intake_schema)

                # 4Ô∏è‚É£ Risk engine
                risk_result = calculate_risk(agent_results)

                # 5Ô∏è‚É£ Explanation engine
                explanation = generate_explanation(risk_result)

                # 6Ô∏è‚É£ Guardrails (mandatory)
                safe_output = apply_full_guardrails(explanation)

                # ---------- UI OUTPUT ----------
                st.success("Analysis completed")

                st.markdown("## üîç Risk Summary")
                st.markdown(f"**Risk Category:** {safe_output['risk_category']}")
                st.markdown(f"**Risk Score:** {safe_output['risk_score']} / 100")
                st.markdown(safe_output["summary"])

                st.markdown("---")
                st.markdown("## üìå Key Observations")
                for item in safe_output["explanations"]:
                    st.markdown(f"- {item}")

                st.markdown("---")
                st.markdown("## üìä Score Breakdown")
                for agent, score in safe_output["breakdown"].items():
                    st.markdown(f"- **{agent.title()}**: {score}")

                st.markdown("---")
                st.markdown("## ‚ö†Ô∏è Disclaimer")
                st.caption(safe_output["disclaimer"])

            except Exception as err:
                st.error("Something went wrong during analysis.")
                st.exception(err)
